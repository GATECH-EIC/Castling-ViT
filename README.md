# Castling-ViT: Compressing Self-Attention via Switching Towards Linear-Angular Attention During Vision Transformer Inference

[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-green)](https://opensource.org/licenses/Apache-2.0)

Haoran You, Yunyang Xiong, Xiaoliang Dai, Bichen Wu, Peizhao Zhang, Haoqi Fan, Peter Vajda, Yingyan Lin

Accepted by [**CVPR 2023**](https://cvpr2023.thecvf.com/). More Info:
\[ [**Paper**](https://arxiv.org/abs/2211.10526) | [**Slide**]() | [**Youtube**]() | [**Github**](https://github.com/GATECH-EIC/Castling-ViT/) \]

---

This is supposed to be an unofficial release of miniature code to reveal the core implementation of our attention block.

Stay tuned for more updates.

---

## Citation

If you find this codebase is useful for your research, please cite:

````
@inproceedings{you2023castling,
  title={Castling-ViT: Compressing Self-Attention via Switching Towards Linear-Angular Attention During Vision Transformer Inference},
  author={You, Haoran and Xiong, Yunyang and Dai, Xiaoliang and Wu, Bichen and Zhang, Peizhao and Fan, Haoqi and Vajda, Peter and Lin, Yingyan},
  booktitle={The IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2023)},
  year={2023}
}
````
